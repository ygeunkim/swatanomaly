% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{kl_dynamic}
\alias{kl_dynamic}
\title{Dynamic lambda Algorithm}
\usage{
kl_dynamic(x, win, jump, lambda_p, eps, display_progress = FALSE)
}
\arguments{
\item{x}{NumericVector univariate data set.}

\item{win}{int window size.}

\item{jump}{int jump size for sliding window.}

\item{lambda_p}{double initializing lambda_p for the threshold.}

\item{eps}{double initializing epsilon for the threshold.}

\item{display_progress}{If TRUE, display a progress bar. By default, FALSE.}
}
\value{
List,
First element is kl divergence named divergence.
Second element is threshold (lambda) for detecting anomaly named threshold.
}
\description{
This function implement dynamic \eqn{\lambda} algorithm for K-L divergence based on gaussianity.
}
\details{
Basically, this algorithm use neighboring-window method.
Slide windows. In each window, estimate a density based on \link[stats]{density.default}.
Between two neighbored window, K-L divergence from current density to previous density can be computed using \code{\link{compute_kl}}.
Given \eqn{\lambda^{\prime}} and \eqn{\epsilon}, set threshold \eqn{\lambda} by \eqn{\lambda = \lambda^{\prime} \epsilon}.
If K-L divergence is less than \eqn{\lambda}, update the threshold by
\deqn{\lambda = \lambda^{\prime} (d_{j - 2} + \epsilon)}
where \eqn{d_{j - 2}} is the K-L divergence two-step before.
Otherwise, keep using the old one.
}
\references{
Cho, J., Tariq, S., Lee, S., Kim, Y. G., & Woo, S. (2019). \emph{Contextual Anomaly Detection by Correlated Probability Distributions using Kullback-Leibler Divergence}. Workshop on Mining and Learning From Time Series. \url{http://doi.org/10.1145/nnnnnnn.nnnnnnn}
}
\seealso{
\link[stats]{density.default}
    \code{\link{est_density}}
    \code{\link{density_cpp}}
    \code{\link{compute_kl}}
}
