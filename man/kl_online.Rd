% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{kl_online}
\alias{kl_online}
\title{Online KL Algorithm}
\usage{
kl_online(x, newx, win, jump, lambda_p, eps, display_progress)
}
\arguments{
\item{x}{NumericVector. univariate data set that consits of non-anomaly.}

\item{newx}{NumericVector. univariate data set that has possibility of anomaly.}

\item{win}{int window size.}

\item{jump}{int jump size for sliding window.}

\item{lambda_p}{double initializing lambda_p for the threshold.}

\item{eps}{double initializing epsilon for the threshold.}

\item{display_progress}{If TRUE, display a progress bar. By default, FALSE.}
}
\value{
List,
First element is kl divergence named divergence.
Second element is threshold (lambda) for detecting anomaly named threshold.
}
\description{
This function implement Dynamic lambda algorithm by online.
}
\details{
This is an online version for dynamic lambda algorithm.
In this setting, normal data set is given. We keep updating new data set that has possibility of anomaly.
This function tries to detect anomaly in this updated set.
First, estimate kernel in the normal set.
Next, estimate kernel in the first window of new data set.
Compute the KL and see if the window is anomaly.
If it is normal, estimate kernel in the normal set including the first window.
Otherwise, just keep the former kernel.
Compute the KL from second window and see if this window is anomaly.
Repeat this procedure while updating lambda.
}
\references{
Cho, J., Tariq, S., Lee, S., Kim, Y. G., & Woo, S. (2019). \emph{Contextual Anomaly Detection by Correlated Probability Distributions using Kullback-Leibler Divergence}. Workshop on Mining and Learning From Time Series. \url{http://doi.org/10.1145/nnnnnnn.nnnnnnn}
}
\seealso{
\link[stats]{density.default}
    \code{\link{est_density}}
    \code{\link{density_cpp}}
    \code{\link{compute_kl}}
    \code{\link{kl_dynamic}}
}
