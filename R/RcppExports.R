# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

rep_bool <- function(x, n) {
    .Call('_swatanomaly_rep_bool', PACKAGE = 'swatanomaly', x, n)
}

detect <- function(y, win, jump, thr) {
    .Call('_swatanomaly_detect', PACKAGE = 'swatanomaly', y, win, jump, thr)
}

#' Aggregate Multivariate Time Series for K-L divergence
#'
#' @description
#' This functions aggregates multivariate times series into univariate time series.
#' See details.
#' @param x NumericMatrix multivariate time series
#' @return NumericVector
#' @details
#' To eliminate local spikes, compute usual distance.
#' \deqn{\sum_{i \neq j}^p \lvert x_{ti} - x_{tj}}
#' where p is the number of variables, and t is the index of time.
#' This enables to explain the correlation between the series.
#' @references Cho, J., Tariq, S., Lee, S., Kim, Y. G., & Woo, S. (2019). \emph{Contextual Anomaly Detection by Correlated Probability Distributions using Kullback-Leibler Divergence}. Workshop on Mining and Learning From Time Series. \url{http://doi.org/10.1145/nnnnnnn.nnnnnnn}
#' @useDynLib swatanomaly
#' @importFrom Rcpp sourceCpp
#' @export
aggregate_mts <- function(x) {
    .Call('_swatanomaly_aggregate_mts', PACKAGE = 'swatanomaly', x)
}

#' Gaussian Kernel Density Estimation in C++
#'
#' @description
#' This function calls \link[stats]{density.default} in Rcpp.
#' Since it calls an R function to Rcpp, it might be slower even than R function itself.
#' This one is just for the sake of defining other functions in Rcpp syntax more easily.
#' @param x NumericVector data for estimation. x of \link[stats]{density.default}.
#' @return NumericMatrix of 2 columns.
#' First column is the n coordinates of the points where the density is estimated (x).
#' Second column is the estimated density values (y).
#' @details
#' Note that \link[stats]{density.default} has various arguments and options.
#' This function, howerver, only computes gaussian kernel.
#' It tries to detect windows derived from other Normal distribution.
#' @seealso
#'    \link[stats]{density.default}
#'    \code{\link{est_density}}
#' @references Cho, J., Tariq, S., Lee, S., Kim, Y. G., & Woo, S. (2019). \emph{Contextual Anomaly Detection by Correlated Probability Distributions using Kullback-Leibler Divergence}. Workshop on Mining and Learning From Time Series. \url{http://doi.org/10.1145/nnnnnnn.nnnnnnn}
#' @useDynLib swatanomaly
#' @importFrom Rcpp sourceCpp
#' @importFrom stats density
#' @export
density_cpp <- function(x) {
    .Call('_swatanomaly_density_cpp', PACKAGE = 'swatanomaly', x)
}

find_support <- function(x1, x2) {
    .Call('_swatanomaly_find_support', PACKAGE = 'swatanomaly', x1, x2)
}

#' Kullback-Leibler divergence estimation between two densities
#'
#' @description
#' This function computes Kullback-Leibler divergence from f2 to f1.
#' When sliding windows, f1 is the previous pdf and f2 is the current pdf.
#' @param f1 NumericMatrix density estimated by \code{\link{est_density}}. previous pdf.
#' @param f2 NumericMatrix density estimated by \code{\link{est_density}}. current pdf.
#' @return double
#' @details
#' Let \eqn{\mathcal{X}} be the support of f1. Then K-L divergence from f2 to f1 is defined by
#' \deqn{E_{X_1} \log \frac{f_1 (x)}{f_2 (x)}}
#' Probability mass is estimated from density by
#' \deqn{f \Delta x}
#' In turn, we can compute K-L divergence using mass p and q by
#' \deqn{\sum_{\mathcal{X}} p(x) \log \frac{p (x)}{q (x)}}
#' To estimate this value, first use \code{\link{est_density}} or \code{\link{density_cpp}}, and estimate density of each window.
#' @seealso
#'     \code{\link{est_density}}
#'     \code{\link{density_cpp}}
#' @references Cho, J., Tariq, S., Lee, S., Kim, Y. G., & Woo, S. (2019). \emph{Contextual Anomaly Detection by Correlated Probability Distributions using Kullback-Leibler Divergence}. Workshop on Mining and Learning From Time Series. \url{http://doi.org/10.1145/nnnnnnn.nnnnnnn}
#' @useDynLib swatanomaly
#' @importFrom Rcpp sourceCpp
#' @export
compute_kl <- function(f1, f2) {
    .Call('_swatanomaly_compute_kl', PACKAGE = 'swatanomaly', f1, f2)
}

#' Fixed lambda Algorithm
#'
#' @description
#' This function implement dynamic \eqn{\lambda} algorithm for K-L divergence based on gaussianity.
#' @param x NumericVector univariate data set.
#' @param win int window size.
#' @param jump int jump size for sliding window.
#' @param lambda double threshold of K-L divergence.
#' @param display_progress If TRUE, display a progress bar. By default, FALSE.
#' @return NumericVector
#' @details
#' Slide windows. In each window, estimate a density based on \link[stats]{density.default}.
#' Between two neighbored window, K-L divergence from current density to previous density can be computed using \code{\link{compute_kl}}.
#' If K-L divergence is less than \eqn{\lambda}, update the threshold by
#' @seealso
#'    \link[stats]{density.default}
#'     \code{\link{est_density}}
#'     \code{\link{density_cpp}}
#'     \code{\link{compute_kl}}
#' @references Cho, J., Tariq, S., Lee, S., Kim, Y. G., & Woo, S. (2019). \emph{Contextual Anomaly Detection by Correlated Probability Distributions using Kullback-Leibler Divergence}. Workshop on Mining and Learning From Time Series. \url{http://doi.org/10.1145/nnnnnnn.nnnnnnn}
#' @useDynLib swatanomaly
#' @importFrom Rcpp sourceCpp
#' @export
kl_fix <- function(x, win, jump, lambda, display_progress = FALSE) {
    .Call('_swatanomaly_kl_fix', PACKAGE = 'swatanomaly', x, win, jump, lambda, display_progress)
}

#' Dynamic lambda Algorithm
#'
#' @description
#' This function implement dynamic \eqn{\lambda} algorithm for K-L divergence based on gaussianity.
#' @param x NumericVector univariate data set.
#' @param win int window size.
#' @param jump int jump size for sliding window.
#' @param lambda_p double initializing lambda_p for the threshold.
#' @param eps double initializing epsilon for the threshold.
#' @param display_progress If TRUE, display a progress bar. By default, FALSE.
#' @return List,
#' First element is kl divergence named divergence.
#' Second element is threshold (lambda) for detecting anomaly named threshold.
#' @details
#' Basically, this algorithm use neighboring-window method.
#' Slide windows. In each window, estimate a density based on \link[stats]{density.default}.
#' Between two neighbored window, K-L divergence from current density to previous density can be computed using \code{\link{compute_kl}}.
#' Given \eqn{\lambda^{\prime}} and \eqn{\epsilon}, set threshold \eqn{\lambda} by \eqn{\lambda = \lambda^{\prime} \epsilon}.
#' If K-L divergence is less than \eqn{\lambda}, update the threshold by
#' \deqn{\lambda = \lambda^{\prime} (d_{j - 2} + \epsilon)}
#' where \eqn{d_{j - 2}} is the K-L divergence two-step before.
#' Otherwise, keep using the old one.
#' @seealso
#'    \link[stats]{density.default}
#'     \code{\link{est_density}}
#'     \code{\link{density_cpp}}
#'     \code{\link{compute_kl}}
#' @references Cho, J., Tariq, S., Lee, S., Kim, Y. G., & Woo, S. (2019). \emph{Contextual Anomaly Detection by Correlated Probability Distributions using Kullback-Leibler Divergence}. Workshop on Mining and Learning From Time Series. \url{http://doi.org/10.1145/nnnnnnn.nnnnnnn}
#' @useDynLib swatanomaly
#' @importFrom Rcpp sourceCpp
#' @export
kl_dynamic <- function(x, win, jump, lambda_p, eps, display_progress = FALSE) {
    .Call('_swatanomaly_kl_dynamic', PACKAGE = 'swatanomaly', x, win, jump, lambda_p, eps, display_progress)
}

#' Matching KL divergence to individual observation
#'
#' @description
#' Give KL divergence values of each window to individual observation.
#' @param d NumeriVector kl divergence vector.
#' @param win int window size.
#' @param jump int jump size for sliding window.
#' @param last_win Fill last window? If TRUE, fill the last window with same value with the KL of the former window. Otherwise, leave them. By default, FALSE.
#' @return NumericVector of number identical to the original series except the last window.
#' @seealso
#'     \code{\link{kl_fix}}
#'     \code{\link{kl_dynamic}}
#' @useDynLib swatanomaly
#' @importFrom Rcpp sourceCpp
#' @export
match_kl <- function(d, win, jump, last_win = FALSE) {
    .Call('_swatanomaly_match_kl', PACKAGE = 'swatanomaly', d, win, jump, last_win)
}

#' Sums of squares in C++
#'
#' @description Compute a SS in C++
#' @param x NumericVector
#' @return double
#' @useDynLib swatanomaly
#' @importFrom Rcpp sourceCpp
#' @export
sum_sq <- function(x) {
    .Call('_swatanomaly_sum_sq', PACKAGE = 'swatanomaly', x)
}

#' Euclidean NND between validation and training blocks
#'
#' @description
#' This function computes NND corresponding to euclidean distance between validation sets and training sets built by cross-validation.
#' @param x NumericMatrix validation set.
#' @param y NumericMatrix training set.
#' @return NumericVector length identical to the validation set
#' @details
#' Consider input x and y. Compute
#' \deqn{\sqrt{\sum (x_{ij} - y_{ij})^2}}
#' for each observation.
#' Calculate Euclidean distance between a point in validation series versus each point in training series.
#' Find minimum value. It is NND.
#' @useDynLib swatanomaly
#' @importFrom Rcpp sourceCpp
#' @export
euc_nnd <- function(x, y) {
    .Call('_swatanomaly_euc_nnd', PACKAGE = 'swatanomaly', x, y)
}

#' Remove row index of a matrix in C++
#'
#' @description
#' This function removes a row index of NumericMatrix in Rcpp.
#' @param x NumericMatrix
#' @param rowID IntegerVector row ids to be removed.
#' @return NumericMatrix
#' @useDynLib swatanomaly
#' @references \url{https://stackoverflow.com/questions/33507695/rcpp-numericmatrix-how-to-erase-a-row-column}
#' @importFrom Rcpp sourceCpp
#' @export
row_erase <- function(x, rowID) {
    .Call('_swatanomaly_row_erase', PACKAGE = 'swatanomaly', x, rowID)
}

#' Sequence by 1 in Rcpp
#'
#' @description
#' This function generates a integer sequence with increment of 1 in Rcpp.
#' @param from int the starting value of the sequence.
#' @param to int the end value of the sequence.
#' @return IntegerVector
#' @useDynLib swatanomaly
#' @importFrom Rcpp sourceCpp
#' @export
seq_rcpp <- function(from, to) {
    .Call('_swatanomaly_seq_rcpp', PACKAGE = 'swatanomaly', from, to)
}

#' Euclidean pdf in Rcpp
#'
#' @description
#' This function computes a euclidean NND pdf of two multivariate series using Rcpp. See details what it is.
#' @param x NumericMatrix, column should indicate variable.
#' @param partition int, equally partitioning the series.
#' @param display_progress If TRUE, display a progress bar. By default, FALSE.
#' @return NumericVector, NND pdf
#' @details
#' Implement k-fold cross-validation. Here, k is partition.
#' First partitioning the series equally.
#' One block is validation set, and the others are trainig.
#' Next for each validation series, it calculates sqrt(sum((x_i - x_j)^2)) versus training series.
#' Find the minimum result for each validation block. This is NND of each block.
#' Finally, you can get NND for every block and this is pdf for NND.
#' For \code{\link{detect_anomaly}}, this pdf is able to threshold.
#' Threshold is a tail of pdf, e.g. 0.99.
#' @seealso
#'    \code{\link{euc_nnd}}
#'    \code{\link{nnd_thr}}
#'    \code{\link{detect_anomaly}}
#' @references
#' Yun, J.-H., Hwang, Y., Lee, W., Ahn, H.-K., & Kim, S.-K. (2018). \emph{Statistical Similarity of Critical Infrastructure Network Traffic Based on Nearest Neighbor Distances} (Vol. 11050, pp. 1–23). Presented at the Research in Attacks, Intrusions, and Defenses, Cham: Springer International Publishing. \url{http://doi.org/10.1007/978-3-030-00470-5_27}
#' @useDynLib swatanomaly
#' @importFrom Rcpp sourceCpp
#' @export
euc_pdf <- function(x, partition, display_progress = FALSE) {
    .Call('_swatanomaly_euc_pdf', PACKAGE = 'swatanomaly', x, partition, display_progress)
}

#' Windowed NNS in Rcpp
#'
#' @description
#' This function computes a windowed NNS.
#' Compute NND sliding window across given series.
#' @param data NumericMatrix multivariate data set
#' @param win int window size for sliding window
#' @param display_progress If TRUE, display a progress bar. By default, FALSE.
#' @return NumericVector, NND for each window index (index represented by its starting point)
#' @details
#' Given n x p data, partition a window.
#' Compute NND for each pair of window.
#' The method is similar to \code{\link{euc_pdf}}.
#' Note that the number of windows is nrow - win + 1 given size of window, win.
#' @references
#' Yun, J.-H., Hwang, Y., Lee, W., Ahn, H.-K., & Kim, S.-K. (2018). \emph{Statistical Similarity of Critical Infrastructure Network Traffic Based on Nearest Neighbor Distances} (Vol. 11050, pp. 1–23). Presented at the Research in Attacks, Intrusions, and Defenses, Cham: Springer International Publishing. \url{http://doi.org/10.1007/978-3-030-00470-5_27}
#' @useDynLib swatanomaly
#' @importFrom Rcpp sourceCpp
#' @export
nns_cpp <- function(data, win, display_progress = FALSE) {
    .Call('_swatanomaly_nns_cpp', PACKAGE = 'swatanomaly', data, win, display_progress)
}

